from mage_ai.data_preparation.decorators import transformer
from sentence_transformers import SentenceTransformer
import pandas as pd

if 'transformer' not in globals():
    from mage_ai.data_preparation.decorators import transformer

@transformer
def transform(data, *args, **kwargs):
    # 1. Initialize the model
    model = SentenceTransformer('all-MiniLM-L6-v2')
    
    chunked_data = []
    
    # 2. Iterate through rows
    # data is a DataFrame, so we convert rows to dictionaries
    for doc in data.to_dict('records'):
        text = str(doc.get('text', ''))
        filename = doc.get('filename', 'unknown')

        # 3. Strategy: Split text into 500-character chunks
        chunks = [text[i:i+500] for i in range(0, len(text), 500)]
        
        for i, chunk in enumerate(chunks):
            # 4. Create the Embedding
            embedding = model.encode(chunk).tolist()
            
            chunked_data.append({
                'document_id': filename,
                'chunk_id': f"{filename}_{i}",
                'content': chunk,
                'vector': embedding
            })
    
    return pd.DataFrame(chunked_data)
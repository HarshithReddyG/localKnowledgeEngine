from sentence_transformers import SentenceTransformer
import pandas as pd

@transformer
def transform(data, *args, **kwargs):
    # 1. Initialize the model
    model = SentenceTransformer('all-MiniLM-L6-v2')
    
    chunked_data = []
    
    # PM Check: If data is a single string (edge case), wrap it in a list
    if isinstance(data, str):
        data = [{'text': data, 'filename': 'unknown_source'}]

    for doc in data:
        # DEFENSIVE CODE: Check if doc is a dictionary or a string
        if isinstance(doc, dict):
            text = doc.get('text', '')
            filename = doc.get('filename', 'unknown')
        else:
            # If doc itself is a string, handle it
            text = str(doc)
            filename = 'unknown'

        # 2. Strategy: Split text into 500-character chunks
        chunks = [text[i:i+500] for i in range(0, len(text), 500)]
        
        for i, chunk in enumerate(chunks):
            # 3. Create the Embedding
            embedding = model.encode(chunk).tolist()
            
            chunked_data.append({
                'document_id': filename,
                'chunk_id': f"{filename}_{i}",
                'content': chunk,
                'vector': embedding
            })
    
    # Convert to DataFrame for the next block (DuckDB)
    return pd.DataFrame(chunked_data)